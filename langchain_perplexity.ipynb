{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U readabilipy langchain openai bs4 requests chromadb tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"langchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"https://www.google.com/search?q={query}\") # Make the request\n",
    "soup = BeautifulSoup(response.text, \"html.parser\") # Parse the HTML\n",
    "links = soup.find_all(\"a\") # Find all the links in the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://api.python.langchain.com/',\n",
       " 'https://aws.amazon.com/what-is/langchain/',\n",
       " 'https://en.wikipedia.org/wiki/LangChain',\n",
       " 'https://github.com/langchain-ai/langchain',\n",
       " 'https://js.langchain.com/docs/get_started/introduction',\n",
       " 'https://pypi.org/project/langchain/',\n",
       " 'https://python.langchain.com/docs/get_started/introduction',\n",
       " 'https://python.langchain.com/docs/get_started/quickstart',\n",
       " 'https://twitter.com/langchainai?lang=en',\n",
       " 'https://www.ibm.com/topics/langchain',\n",
       " 'https://www.langchain.com/',\n",
       " 'https://www.techtarget.com/searchenterpriseai/definition/LangChain']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_links(links):\n",
    "    urls = []\n",
    "    for link in links:\n",
    "        if link[\"href\"].startswith(\"/url?q=\"):\n",
    "            url = link[\"href\"].replace(\"/url?q=\", \"\")\n",
    "            url = unquote(url.split(\"&sa=\")[0])\n",
    "            if url.startswith(\"https://scholar.google.com/scholar_url?url=http\"):\n",
    "                url = url.replace(\"https://scholar.google.com/scholar_url?url=\", \"\").split(\"&\")[0]\n",
    "            elif 'google.com/' in url or url.endswith('.pdf'):\n",
    "                continue\n",
    "            if '#' in url:\n",
    "                url = url.split('#')[0]\n",
    "            if url.startswith('http://') or url.startswith('https://'):\n",
    "                urls.append(url)\n",
    "    return urls\n",
    "\n",
    "urls = filter_links(links)\n",
    "urls = list(np.unique(urls)) # Use numpy to dedupe the list of urls after removing anchors\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML -> text\n",
    "from readabilipy import simple_json_from_html_string \n",
    "from langchain.schema import Document\n",
    "from typing import Optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_parse(url: str) -> Optional[Document]:\n",
    "    \"\"\"Scrape a webpage and parse it into a Document object\"\"\"\n",
    "    try:\n",
    "        req = requests.get(url)\n",
    "        article = simple_json_from_html_string(req.text, use_readability=True)\n",
    "        \n",
    "        if not article['plain_text']:\n",
    "            print(f\"No plain text found in the article from {url}\")\n",
    "            return None\n",
    "        \n",
    "        return Document(page_content='\\n\\n'.join([a['text'] for a in article['plain_text']]), metadata={'source': url, 'page_title': article['title']})\n",
    "    except (requests.exceptions.RequestException, Exception) as e:\n",
    "        print(f\"Error occurred while processing {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No plain text found in the article from https://pypi.org/project/langchain/\n",
      "No plain text found in the article from https://python.langchain.com/docs/get_started/quickstart\n",
      "No plain text found in the article from https://python.langchain.com/docs/get_started/introduction\n",
      "No plain text found in the article from https://www.langchain.com/\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# This requires nodejs \n",
    "# You can install it like so: curl -sL https://deb.nodesource.com/setup_lts.x | sudo -E bash - && sudo apt-get install -y nodejs\n",
    "documents = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    future_to_url = {executor.submit(scrape_and_parse, url): url for url in urls}\n",
    "    for future in as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            doc = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'{url} generated an exception: {exc}')\n",
    "        else:\n",
    "            if doc:\n",
    "                documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=' ', chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"Who created langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What is LangChain? LangChain is an open source framework that lets software developers working with artificial intelligence (AI) and its machine learning subset combine large language models with other external components to develop LLM-powered applications. The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications. Developers, software engineers and data scientists with experience in the Python, JavaScript or TypeScript programming languages can make use of LangChain's packages offered in those languages. LangChain was launched as an open source project by co-founders Harrison Chase and Ankush Gola in 2022; the initial version was released that same year. Why is LangChain important? LangChain is a framework that simplifies the process of creating generative AI application interfaces. Developers working on these types of interfaces use various\\n\\n2023\\n\\nThis was last updated in September 2023\\n\\nWhat is LangChain? LangChain is an open source framework that lets software developers working with artificial intelligence (AI) and its machine learning subset combine large language models with other external components to develop LLM-powered applications. The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications. Developers, software engineers and data scientists with experience in the Python, JavaScript or TypeScript programming languages can make use of LangChain's packages offered in those languages. LangChain was launched as an open source project by co-founders Harrison Chase and Ankush Gola in 2022; the initial version was released that same year. Why is LangChain important? LangChain is a framework that simplifies the process of creating generative AI application interfaces. Developers\\n\\nopen source project by co-founders Harrison Chase and Ankush Gola in 2022; the initial version was released that same year.\\n\\nDevelopers, software engineers and data scientists with experience in the Python, JavaScript or TypeScript programming languages can make use of LangChain's packages offered in those languages. LangChain was launched as an open source project by co-founders Harrison Chase and Ankush Gola in 2022; the initial version was released that same year.\\n\\nWhat is LangChain? LangChain is an open source framework that lets software developers working with artificial intelligence (AI) and its machine learning subset combine large language models with other external components to develop LLM-powered applications. The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications. Developers, software engineers and data scientists with\\n\\nAdrian Bridgwater, * Compare 8 prompt engineering tools By: Emily Foster, * DataStax LangChain integration builds new link to gen-AI for developers By: Adrian Bridgwater,\\n\\nWhat is LangChain? LangChain is an open source framework that lets software developers working with artificial intelligence (AI) and its machine learning subset combine large language models with other external components to develop LLM-powered applications. The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications. Developers, software engineers and data scientists with experience in the Python, JavaScript or TypeScript programming languages can make use of LangChain's packages offered in those languages. LangChain was launched as an open source project by co-founders Harrison Chase and Ankush Gola in 2022; the initial version was released that same year. Why is LangChain\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "query = \"Why is langchain useful?\"\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=retriever)\n",
    "result = chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LangChain is useful for several reasons:\\n'\n",
      " '\\n'\n",
      " '1. Simplifies the development process: LangChain provides a framework that '\n",
      " 'simplifies the process of creating generative AI application interfaces. It '\n",
      " 'streamlines the development of advanced natural language processing (NLP) '\n",
      " 'applications by providing tools and packages that developers can use.\\n'\n",
      " '\\n'\n",
      " '2. Combines powerful language models with external data sources: LangChain '\n",
      " \"allows developers to link powerful language models, such as OpenAI's GPT-3.5 \"\n",
      " 'and GPT-4, with external data sources. This enables the creation of '\n",
      " 'LLM-powered applications that can leverage the benefits of natural language '\n",
      " 'processing.\\n'\n",
      " '\\n'\n",
      " '3. Enables the creation of NLP applications: LangChain empowers developers, '\n",
      " 'software engineers, and data scientists with the ability to create NLP '\n",
      " 'applications. These applications can understand and process natural '\n",
      " 'language, enabling tasks such as diagnosing medical conditions, automating '\n",
      " 'administrative tasks, and improving marketing and e-commerce experiences.\\n'\n",
      " '\\n'\n",
      " '4. Organizes and accesses large volumes of data: LangChain helps organize '\n",
      " 'and access large quantities of data required by LLMs. This makes it easier '\n",
      " 'for language models to access the necessary data for training and '\n",
      " 'inference.\\n'\n",
      " '\\n'\n",
      " '5. Provides up-to-date knowledge: LangChain can connect AI models to data '\n",
      " 'sources, allowing them to have knowledge of recent data without limitations. '\n",
      " 'This ensures that the language models have access to the latest information '\n",
      " 'and can provide accurate and relevant responses.\\n'\n",
      " '\\n'\n",
      " 'Overall, LangChain is useful for simplifying the development of generative '\n",
      " 'AI applications, combining language models with external data sources, and '\n",
      " 'enabling the creation of NLP applications in various domains.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
